import os
import re
import webbrowser
from PIL import Image
from Agent_Marketplace.utils import smart_resize, encode_image, draw_point
import time

def make_screenshot(page, output_image_path):
    time.sleep(2)
    page.screenshot(path=output_image_path)
    return page


def open_browser(p):
    browser = p.chromium.launch(headless=False)
    # Ð¸Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ ÑÑ‚Ñ€Ð°Ð½Ð¸Ñ†Ñ‹
    page = browser.new_page()
    # Ð¿ÐµÑ€ÐµÑ…Ð¾Ð´ Ð¿Ð¾ url Ð°Ð´Ñ€ÐµÑÑƒ:
    page.goto('https://market.yandex.ru/')
    return browser, page


def click(
        page,
        screenshot_path,
        user_query,
        client_openai,
        model_id,
        output_image_path="screenshot_annotated2.png",
        min_pixels=3136,
        max_pixels=12845056,
        pretty_click = False

):
    """Tool ÐºÐ»Ð¸ÐºÐ° Ð¿Ð¾ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸ÑŽ: Ð²Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÑ‚ ÑÐ¿Ð¸ÑÐ¾Ðº ÐºÐ¾Ð¾Ñ€Ð´Ð¸Ð½Ð°Ñ‚ [x, y]"""

    input_image = Image.open(screenshot_path)

    # --- Smart resize: Ð¾Ð±ÑÐ·Ð°Ñ‚ÐµÐ»ÑŒÐ½Ð¾ Ð´Ð»Ñ Qwen3-VL ---
    resized_h, resized_w = smart_resize(
        input_image.height,
        input_image.width,
        factor=32,
        min_pixels=min_pixels,
        max_pixels=max_pixels,
    )
    resized_image = input_image.resize((resized_w, resized_h))

    base64_image = encode_image(screenshot_path)

    # Ð¡Ð¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ñ Ð´Ð»Ñ Ð¼Ð¾Ð´ÐµÐ»Ð¸
    messages = [
        {
            "role": "user",
            "content": [
                {
                    "type": "image_url",
                    "image_url": {"url": f"data:image/png;base64,{base64_image}"},
                },
                {"type": "text", "text": user_query},
            ],
        }
    ]

    # Ð—Ð°Ð¿Ñ€Ð¾Ñ Ðº Ð¼Ð¾Ð´ÐµÐ»Ð¸
    completion = client_openai.chat.completions.create(
        model=model_id,
        messages=messages,
        max_tokens=500,
    )

    output_text = completion.choices[0].message.content
    print("\n=== Model Output ===")
    print(output_text)

    # =================================================================
    #   Ð˜Ð—Ð’Ð›Ð•Ð§Ð•ÐÐ˜Ð• ÐšÐžÐžÐ Ð”Ð˜ÐÐÐ¢ (Qwen Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚ â€” Ð¾Ñ‚Ð½Ð¾ÑÐ¸Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ðµ 0â€“1000)
    # =================================================================

    coordinate_absolute = None

    # Bounding-box
    bbox = re.search(r'\[([0-9]+),\s*([0-9]+),\s*([0-9]+),\s*([0-9]+)\]', output_text)
    if bbox:
        x1, y1, x2, y2 = map(int, bbox.groups())
        rel_x = (x1 + x2) // 2
        rel_y = (y1 + y2) // 2
        print(f"Extracted bbox â†’ center = ({rel_x}, {rel_y})")

    # Ð¢Ð¾Ð»ÑŒÐºÐ¾ Ñ‚Ð¾Ñ‡ÐºÐ°
    else:
        pt = re.search(r'\[([0-9]+),\s*([0-9]+)\]', output_text)
        if pt:
            rel_x, rel_y = map(int, pt.groups())
            print(f"Extracted point = ({rel_x}, {rel_y})")
        else:
            print(" Could not parse point or bbox from model output")
            return output_text, None

    # --- ÐŸÐµÑ€ÐµÐ²Ð¾Ð´ Ð¾Ñ‚Ð½Ð¾ÑÐ¸Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ñ… ÐºÐ¾Ð¾Ñ€Ð´Ð¸Ð½Ð°Ñ‚ (0â€“1000) â†’ Ð¿Ð¸ÐºÑÐµÐ»Ð¸ resized Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ ---
    abs_x = rel_x / 1000 * resized_w
    abs_y = rel_y / 1000 * resized_h
    coordinate_absolute = [abs_x, abs_y]

    # =================================================================
    #       Ð Ð˜Ð¡Ð£Ð•Ðœ Ð¢ÐžÐ§ÐšÐ£ ÐÐ RESIZED Ð˜Ð—ÐžÐ‘Ð ÐÐ–Ð•ÐÐ˜Ð˜
    # =================================================================

    annotated = draw_point(resized_image, coordinate_absolute, color="green")
    if pretty_click:
        annotated.save(output_image_path, quality=95)

        print(f"\nAnnotated image saved to: {os.path.abspath(output_image_path)}")

    if os.path.exists(output_image_path):
        webbrowser.open(f"file://{os.path.abspath(output_image_path)}")

    # --- ÐŸÐµÑ€ÐµÐ²Ð¾Ð´ Ð¾Ñ‚Ð½Ð¾ÑÐ¸Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ñ… ÐºÐ¾Ð¾Ñ€Ð´Ð¸Ð½Ð°Ñ‚ (0â€“1000) â†’ Ð¿Ð¸ÐºÑÐµÐ»Ð¸ ÐžÐ Ð˜Ð“Ð˜ÐÐÐ›Ð¬ÐÐžÐ“Ðž viewport'Ð° ---
    x_on_page = rel_x / 1000 * input_image.width
    y_on_page = rel_y / 1000 * input_image.height

    print(f"Clicking at ({x_on_page:.1f}, {y_on_page:.1f}) on page (viewport px)")

    page.mouse.click(x_on_page, y_on_page)
    return page

def click_and_type(
    page,
    screenshot_path,
    user_query,
    client_openai,
    model_id,
    text_to_type,
    output_image_path="screenshot_annotated_input.png",
    min_pixels=3136,
    max_pixels=12845056,
    pretty_click=False,
    press_enter=True,
):
    """
    Tool: Ð½Ð°Ñ…Ð¾Ð´Ð¸Ñ‚ ÑÐ»ÐµÐ¼ÐµÐ½Ñ‚ Ð¿Ð¾ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸ÑŽ (Ð½Ð°Ð¿Ñ€Ð¸Ð¼ÐµÑ€, ÑÑ‚Ñ€Ð¾ÐºÑƒ Ð¿Ð¾Ð¸ÑÐºÐ°), ÐºÐ»Ð¸ÐºÐ°ÐµÑ‚ Ð² Ð½ÐµÐ³Ð¾ Ð¸ Ð²Ð²Ð¾Ð´Ð¸Ñ‚ Ñ‚ÐµÐºÑÑ‚.

    Args:
        page: Playwright page object
        screenshot_path: Ð¿ÑƒÑ‚ÑŒ Ðº ÑÐºÑ€Ð¸Ð½ÑˆÐ¾Ñ‚Ñƒ Ð´Ð»Ñ Ð°Ð½Ð°Ð»Ð¸Ð·Ð°
        user_query: Ð¿Ñ€Ð¾Ð¼Ð¿Ñ‚ Ð´Ð»Ñ Ð¼Ð¾Ð´ÐµÐ»Ð¸ (Ð½Ð°Ð¿Ñ€Ð¸Ð¼ÐµÑ€, "ÐÐ°Ð¹Ð´Ð¸ ÐºÐ¾Ð¾Ñ€Ð´Ð¸Ð½Ð°Ñ‚Ñ‹ ÑÑ‚Ñ€Ð¾ÐºÐ¸ Ð¿Ð¾Ð¸ÑÐºÐ° Ð² Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ðµ [x, y]")
        client_openai: OpenAI-ÑÐ¾Ð²Ð¼ÐµÑÑ‚Ð¸Ð¼Ñ‹Ð¹ ÐºÐ»Ð¸ÐµÐ½Ñ‚
        model_id: ID Ð¼Ð¾Ð´ÐµÐ»Ð¸ (Ð½Ð°Ð¿Ñ€Ð¸Ð¼ÐµÑ€, "Qwen/Qwen3-VL-...")
        text_to_type: Ñ‚ÐµÐºÑÑ‚, ÐºÐ¾Ñ‚Ð¾Ñ€Ñ‹Ð¹ Ð½ÑƒÐ¶Ð½Ð¾ Ð²Ð²ÐµÑÑ‚Ð¸ Ð¿Ð¾ÑÐ»Ðµ ÐºÐ»Ð¸ÐºÐ°
        output_image_path: ÐºÑƒÐ´Ð° ÑÐ¾Ñ…Ñ€Ð°Ð½Ð¸Ñ‚ÑŒ Ð°Ð½Ð½Ð¾Ñ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ð¹ ÑÐºÑ€Ð¸Ð½ÑˆÐ¾Ñ‚
        min_pixels / max_pixels: Ð¿Ð°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ñ‹ smart_resize (Ð´Ð»Ñ Qwen-VL)
        pretty_click: Ñ€Ð¸ÑÐ¾Ð²Ð°Ñ‚ÑŒ Ð»Ð¸ Ñ‚Ð¾Ñ‡ÐºÑƒ Ð¸ Ð¾Ñ‚ÐºÑ€Ñ‹Ð²Ð°Ñ‚ÑŒ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ðµ
        press_enter: Ð½Ð°Ð¶Ð¸Ð¼Ð°Ñ‚ÑŒ Ð»Ð¸ Enter Ð¿Ð¾ÑÐ»Ðµ Ð²Ð²Ð¾Ð´Ð°

    Returns:
        page: Ð¾Ð±Ð½Ð¾Ð²Ð»Ñ‘Ð½Ð½Ñ‹Ð¹ page object
    """

    input_image = Image.open(screenshot_path)

    # --- Smart resize: Ð¾Ð±ÑÐ·Ð°Ñ‚ÐµÐ»ÑŒÐ½Ð¾ Ð´Ð»Ñ Qwen3-VL ---
    resized_h, resized_w = smart_resize(
        input_image.height,
        input_image.width,
        factor=32,
        min_pixels=min_pixels,
        max_pixels=max_pixels,
    )
    resized_image = input_image.resize((resized_w, resized_h))

    base64_image = encode_image(screenshot_path)

    # Ð¡Ð¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ñ Ð´Ð»Ñ Ð¼Ð¾Ð´ÐµÐ»Ð¸
    messages = [
        {
            "role": "user",
            "content": [
                {
                    "type": "image_url",
                    "image_url": {"url": f"data:image/png;base64,{base64_image}"},
                },
                {"type": "text", "text": user_query},
            ],
        }
    ]

    # Ð—Ð°Ð¿Ñ€Ð¾Ñ Ðº Ð¼Ð¾Ð´ÐµÐ»Ð¸
    completion = client_openai.chat.completions.create(
        model=model_id,
        messages=messages,
        max_tokens=500,
    )

    output_text = completion.choices[0].message.content
    print("\n=== Model Output (click_and_type) ===")
    print(output_text)

    # =================================================================
    #   Ð˜Ð—Ð’Ð›Ð•Ð§Ð•ÐÐ˜Ð• ÐšÐžÐžÐ Ð”Ð˜ÐÐÐ¢ (Qwen Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚ â€” Ð¾Ñ‚Ð½Ð¾ÑÐ¸Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ðµ 0â€“1000)
    # =================================================================

    rel_x = rel_y = None

    # Bounding-box
    bbox = re.search(r'\[([0-9]+),\s*([0-9]+),\s*([0-9]+),\s*([0-9]+)\]', output_text)
    if bbox:
        x1, y1, x2, y2 = map(int, bbox.groups())
        rel_x = (x1 + x2) // 2
        rel_y = (y1 + y2) // 2
        print(f"Extracted bbox â†’ center = ({rel_x}, {rel_y})")

    # Ð¢Ð¾Ð»ÑŒÐºÐ¾ Ñ‚Ð¾Ñ‡ÐºÐ°
    else:
        pt = re.search(r'\[([0-9]+),\s*([0-9]+)\]', output_text)
        if pt:
            rel_x, rel_y = map(int, pt.groups())
            print(f"Extracted point = ({rel_x}, {rel_y})")
        else:
            print("âŒ Could not parse point or bbox from model output")
            return page  # or raise ValueError

    # --- ÐŸÐµÑ€ÐµÐ²Ð¾Ð´ Ð¾Ñ‚Ð½Ð¾ÑÐ¸Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ñ… ÐºÐ¾Ð¾Ñ€Ð´Ð¸Ð½Ð°Ñ‚ (0â€“1000) â†’ Ð¿Ð¸ÐºÑÐµÐ»Ð¸ viewport'Ð° (Ð¾Ñ€Ð¸Ð³Ð¸Ð½Ð°Ð»Ð°) ---
    x_on_page = rel_x / 1000 * input_image.width
    y_on_page = rel_y / 1000 * input_image.height

    print(f"ðŸ–±ï¸  Clicking at ({x_on_page:.1f}, {y_on_page:.1f}) on page (viewport {input_image.width}Ã—{input_image.height})")

    # --- ÐšÐ»Ð¸Ðº ---
    page.mouse.click(x_on_page, y_on_page)
    time.sleep(0.3)  # Ð´Ð°Ñ‚ÑŒ Ñ„Ð¾ÐºÑƒÑ ÑƒÑÑ‚Ð°Ð½Ð¾Ð²Ð¸Ñ‚ÑŒÑÑ

    # --- Ð’Ð²Ð¾Ð´ Ñ‚ÐµÐºÑÑ‚Ð° ---
    print(f"âŒ¨ï¸  Typing: '{text_to_type}'")
    page.keyboard.type(text_to_type, delay=50)  # delay Ð¸Ð¼Ð¸Ñ‚Ð¸Ñ€ÑƒÐµÑ‚ Ñ‡ÐµÐ»Ð¾Ð²ÐµÑ‡ÐµÑÐºÑƒÑŽ ÑÐºÐ¾Ñ€Ð¾ÑÑ‚ÑŒ

    # --- ÐÐ°Ð¶Ð°Ñ‚Ð¸Ðµ Enter (Ð¾Ð¿Ñ†Ð¸Ð¾Ð½Ð°Ð»ÑŒÐ½Ð¾) ---
    if press_enter:
        print("âŽ  Pressing Enter")
        page.keyboard.press("Enter")

    # =================================================================
    #       Ð Ð˜Ð¡Ð£Ð•Ðœ Ð¢ÐžÐ§ÐšÐ£ ÐÐ RESIZED Ð˜Ð—ÐžÐ‘Ð ÐÐ–Ð•ÐÐ˜Ð˜ (Ð´Ð»Ñ Ð¾Ñ‚Ð»Ð°Ð´ÐºÐ¸)
    # =================================================================

    # ÐšÐ¾Ð¾Ñ€Ð´Ð¸Ð½Ð°Ñ‚Ñ‹ Ð´Ð»Ñ Ð°Ð½Ð½Ð¾Ñ‚Ð°Ñ†Ð¸Ð¸ â€” Ð½Ð° resized Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ð¸
    abs_x_annot = rel_x / 1000 * resized_w
    abs_y_annot = rel_y / 1000 * resized_h

    annotated = draw_point(resized_image, [abs_x_annot, abs_y_annot], color="blue")
    if pretty_click:
        annotated.save(output_image_path, quality=95)
        print(f"\nðŸ–¼ï¸  Annotated image saved to: {os.path.abspath(output_image_path)}")
        webbrowser.open(f"file://{os.path.abspath(output_image_path)}")

    return page
def scroll(
    page,
    direction="down",
    amount=300,
    smooth=True,
    delay_after=0.8
):
    if direction not in ("up", "down"):
        raise ValueError("direction must be 'up' or 'down'")

    scroll_delta = -amount if direction == "up" else amount

    current_scroll_y = page.evaluate("window.scrollY")
    new_scroll_y = max(0, current_scroll_y + scroll_delta)

    print(f"ðŸ–±ï¸  Scroll {direction} by {amount}px â†’ from Y={current_scroll_y:.0f} to Y={new_scroll_y:.0f}")

    if smooth:
        # âœ… ÐŸÐ ÐÐ’Ð˜Ð›Ð¬ÐÐž: Ð¿ÐµÑ€ÐµÐ´Ð°Ñ‘Ð¼ Ñ„ÑƒÐ½ÐºÑ†Ð¸ÑŽ + Ð°Ñ€Ð³ÑƒÐ¼ÐµÐ½Ñ‚
        page.evaluate(
            """(y) => {
                window.scrollTo({
                    top: y,
                    behavior: 'smooth'
                });
            }""",
            new_scroll_y
        )
    else:
        # âœ… Ð¢Ð°ÐºÐ¶Ðµ ÐºÐ¾Ñ€Ñ€ÐµÐºÑ‚Ð½Ð¾
        page.evaluate("window.scrollTo(0, arguments[0])", new_scroll_y)

    time.sleep(delay_after)
    return page
